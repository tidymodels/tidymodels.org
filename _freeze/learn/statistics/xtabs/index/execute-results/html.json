{
  "hash": "33fb39003f1fa94a3679e6c404faee52",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Statistical analysis of contingency tables\"\ncategories:\n  - statistical analysis\n  - analysis of tables\n  - hypothesis testing\ntype: learn-subsection\nweight: 5\ndescription: | \n  Use tests of independence and goodness of fit to analyze tables of counts.\ntoc: true\ntoc-depth: 2\ninclude-after-body: ../../../resources.html\n---\n\n\n\n\n\n\n\n## Introduction\n\nThis article only requires that you have the tidymodels package installed.\n\nIn this vignette, we'll walk through conducting a $\\chi^2$ (chi-squared) test of independence and a chi-squared goodness of fit test using infer. We'll start out with a chi-squared test of independence, which can be used to test the association between two categorical variables. Then, we'll move on to a chi-squared goodness of fit test, which tests how well the distribution of one categorical variable can be approximated by some theoretical distribution.\n\nThroughout this vignette, we'll make use of the `ad_data` data set (available in the modeldata package, which is part of tidymodels). This data set is related to cognitive impairment in 333 patients from [Craig-Schapiro _et al_ (2011)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3079734/). See `?ad_data` for more information on the variables included and their source. One of the main research questions in these data were how a person's genetics related to the Apolipoprotein E gene affect their cognitive skills. The data shows: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidymodels) # Includes the infer package\n\ndata(ad_data, package = \"modeldata\")\nad_data %>%\n  select(Genotype, Class)\n#> # A tibble: 333 × 2\n#>    Genotype Class   \n#>    <fct>    <fct>   \n#>  1 E3E3     Control \n#>  2 E3E4     Control \n#>  3 E3E4     Control \n#>  4 E3E4     Control \n#>  5 E3E3     Control \n#>  6 E4E4     Impaired\n#>  7 E2E3     Control \n#>  8 E2E3     Control \n#>  9 E3E3     Control \n#> 10 E2E3     Impaired\n#> # ℹ 323 more rows\n```\n:::\n\n\nThe three main genetic variants are called E2, E3, and E4. The values in `Genotype` represent the genetic makeup of patients based on what they inherited from their parents (i.e, a value of \"E2E4\" means E2 from one parent and E4 from the other). \n\n## Test of independence\n\nTo carry out a chi-squared test of independence, we'll examine the association between their cognitive ability (impaired and healthy) and the genetic makeup. This is what the relationship looks like in the sample data:\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](figs/plot-indep-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\nIf there were no relationship, we would expect to see the purple bars reaching to the same length, regardless of cognitive ability. Are the differences we see here, though, just due to random noise?\n\nFirst, to calculate the observed statistic, we can use `specify()` and `calculate()`.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# calculate the observed statistic\nobserved_indep_statistic <- ad_data %>%\n  specify(Genotype ~ Class) %>%\n  calculate(stat = \"Chisq\")\n```\n:::\n\n\nThe observed $\\chi^2$ statistic is 21.5774809. Now, we want to compare this statistic to a null distribution, generated under the assumption that these variables are not actually related, to get a sense of how likely it would be for us to see this observed statistic if there were actually no association between cognitive ability and genetics.\n\nWe can `generate()` the null distribution in one of two ways: using randomization or theory-based methods. The randomization approach permutes the response and explanatory variables, so that each person's genetics is matched up with a random cognitive rating from the sample in order to break up any association between the two.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# generate the null distribution using randomization\nnull_distribution_simulated <- ad_data %>%\n  specify(Genotype ~ Class) %>%\n  hypothesize(null = \"independence\") %>%\n  generate(reps = 5000, type = \"permute\") %>%\n  calculate(stat = \"Chisq\")\n```\n:::\n\n\nNote that, in the line `specify(Genotype ~ Class)` above, we could use the equivalent syntax `specify(response = Genotype, explanatory = Class)`. The same goes in the code below, which generates the null distribution using theory-based methods instead of randomization.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# generate the null distribution by theoretical approximation\nnull_distribution_theoretical <- ad_data %>%\n  specify(Genotype ~ Class) %>%\n  hypothesize(null = \"independence\") %>%\n  # note that we skip the generation step here!\n  calculate(stat = \"Chisq\")\n```\n:::\n\n\nTo get a sense for what these distributions look like, and where our observed statistic falls, we can use `visualize()`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# visualize the null distribution and test statistic!\nnull_distribution_simulated %>%\n  visualize() + \n  shade_p_value(observed_indep_statistic,\n                direction = \"greater\")\n```\n\n::: {.cell-output-display}\n![](figs/visualize-indep-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\nWe could also visualize the observed statistic against the theoretical null distribution. Note that we skip the `generate()` and `calculate()` steps when using the theoretical approach, and that we now need to provide `method = \"theoretical\"` to `visualize()`.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# visualize the theoretical null distribution and test statistic!\nad_data %>%\n  specify(Genotype ~ Class) %>%\n  hypothesize(null = \"independence\") %>%\n  visualize(method = \"theoretical\") + \n  shade_p_value(observed_indep_statistic,\n                direction = \"greater\")\n```\n\n::: {.cell-output-display}\n![](figs/visualize-indep-theor-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\nTo visualize both the randomization-based and theoretical null distributions to get a sense of how the two relate, we can pipe the randomization-based null distribution into `visualize()`, and further provide `method = \"both\"`.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# visualize both null distributions and the test statistic!\nnull_distribution_simulated %>%\n  visualize(method = \"both\") + \n  shade_p_value(observed_indep_statistic,\n                direction = \"greater\")\n```\n\n::: {.cell-output-display}\n![](figs/visualize-indep-both-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\nEither way, it looks like our observed test statistic would be fairly unlikely if there were actually no association between cognition and genotype. More exactly, we can calculate the p-value:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# calculate the p value from the observed statistic and null distribution\np_value_independence <- null_distribution_simulated %>%\n  get_p_value(obs_stat = observed_indep_statistic,\n              direction = \"greater\")\n\np_value_independence\n#> # A tibble: 1 × 1\n#>   p_value\n#>     <dbl>\n#> 1  0.0006\n```\n:::\n\n\nThus, if there were really no relationship between cognition and genotype, the probability that we would see a statistic as or more extreme than 21.5774809 is approximately 6\\times 10^{-4}.\n\nNote that, equivalently to the steps shown above, the package supplies a wrapper function, `chisq_test`, to carry out Chi-Squared tests of independence on tidy data. The syntax goes like this:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nchisq_test(ad_data, Genotype ~ Class)\n#> # A tibble: 1 × 3\n#>   statistic chisq_df  p_value\n#>       <dbl>    <int>    <dbl>\n#> 1      21.6        5 0.000630\n```\n:::\n\n\n\n## Goodness of fit\n\nNow, moving on to a chi-squared goodness of fit test, we'll take a look at just the genotype data. Many papers have investigated the relationship of Apolipoprotein E to diseases. For example, [Song _et al_ (2004)](https://annals.org/aim/article-abstract/717641/meta-analysis-apolipoprotein-e-genotypes-risk-coronary-heart-disease) conducted a meta-analysis of numerous studies that looked at this gene and heart disease. In their paper, they describe the frequency of the different genotypes across many samples. For the cognition study, it might be interesting to see if our sample of genotypes was consistent with this literature (treating the rates, for this analysis, as known). \n\nThe rates of the meta-analysis and our observed data are: \n \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Song, Y., Stampfer, M. J., & Liu, S. (2004). Meta-Analysis: Apolipoprotein E \n# Genotypes and Risk for Coronary Heart Disease. Annals of Internal Medicine, \n# 141(2), 137.\nmeta_rates <- c(\"E2E2\" = 0.71, \"E2E3\" = 11.4, \"E2E4\" = 2.32,\n                \"E3E3\" = 61.0, \"E3E4\" = 22.6, \"E4E4\" = 2.22)\nmeta_rates <- meta_rates/sum(meta_rates) # these add up to slightly > 100%\n\nobs_rates <- table(ad_data$Genotype)/nrow(ad_data)\nround(cbind(obs_rates, meta_rates) * 100, 2)\n#>      obs_rates meta_rates\n#> E2E2      0.60       0.71\n#> E2E3     11.11      11.37\n#> E2E4      2.40       2.31\n#> E3E3     50.15      60.85\n#> E3E4     31.83      22.54\n#> E4E4      3.90       2.21\n```\n:::\n\n\nSuppose our null hypothesis is that `Genotype` follows the same frequency distribution as the meta-analysis. Lets now test whether this difference in distributions is statistically significant.\n\nFirst, to carry out this hypothesis test, we would calculate our observed statistic.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# calculating the null distribution\nobserved_gof_statistic <- ad_data %>%\n  specify(response = Genotype) %>%\n  hypothesize(null = \"point\", p = meta_rates) %>%\n  calculate(stat = \"Chisq\")\n```\n:::\n\n\nThe observed statistic is 23.3838483. Now, generating a null distribution, by just dropping in a call to `generate()`:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# generating a null distribution\nnull_distribution_gof <- ad_data %>%\n  specify(response = Genotype) %>%\n  hypothesize(null = \"point\", p = meta_rates) %>%\n  generate(reps = 5000, type = \"simulate\") %>%\n  calculate(stat = \"Chisq\")\n```\n:::\n\n\nAgain, to get a sense for what these distributions look like, and where our observed statistic falls, we can use `visualize()`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# visualize the null distribution and test statistic!\nnull_distribution_gof %>%\n  visualize() + \n  shade_p_value(observed_gof_statistic,\n                direction = \"greater\")\n```\n\n::: {.cell-output-display}\n![](figs/visualize-indep-gof-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\nThis statistic seems like it would be unlikely if our rates were the same as the rates from the meta-analysis! How unlikely, though? Calculating the p-value:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# calculate the p-value\np_value_gof <- null_distribution_gof %>%\n  get_p_value(observed_gof_statistic,\n              direction = \"greater\")\n\np_value_gof\n#> # A tibble: 1 × 1\n#>   p_value\n#>     <dbl>\n#> 1  0.0016\n```\n:::\n\n\nThus, if each genotype occurred at the same rate as the Song paper, the probability that we would see a distribution like the one we did is approximately 0.0016.\n\nAgain, equivalently to the steps shown above, the package supplies a wrapper function, `chisq_test`, to carry out chi-squared goodness of fit tests on tidy data. The syntax goes like this:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nchisq_test(ad_data, response = Genotype, p = meta_rates)\n#> # A tibble: 1 × 3\n#>   statistic chisq_df  p_value\n#>       <dbl>    <dbl>    <dbl>\n#> 1      23.4        5 0.000285\n```\n:::\n\n\n\n\n## Session information {#session-info}\n\n\n::: {.cell layout-align=\"center\"}\n\n```\n#> ─ Session info ─────────────────────────────────────────────────────\n#>  setting  value\n#>  version  R version 4.3.3 (2024-02-29)\n#>  os       macOS Sonoma 14.4.1\n#>  system   aarch64, darwin20\n#>  ui       X11\n#>  language (EN)\n#>  collate  en_US.UTF-8\n#>  ctype    en_US.UTF-8\n#>  tz       America/Los_Angeles\n#>  date     2024-03-26\n#>  pandoc   2.17.1.1 @ /opt/homebrew/bin/ (via rmarkdown)\n#> \n#> ─ Packages ─────────────────────────────────────────────────────────\n#>  package    * version date (UTC) lib source\n#>  broom      * 1.0.5   2023-06-09 [1] CRAN (R 4.3.0)\n#>  dials      * 1.2.1   2024-02-22 [1] CRAN (R 4.3.1)\n#>  dplyr      * 1.1.4   2023-11-17 [1] CRAN (R 4.3.1)\n#>  ggplot2    * 3.5.0   2024-02-23 [1] CRAN (R 4.3.1)\n#>  infer      * 1.0.7   2024-03-25 [1] CRAN (R 4.3.1)\n#>  parsnip    * 1.2.1   2024-03-22 [1] CRAN (R 4.3.1)\n#>  purrr      * 1.0.2   2023-08-10 [1] CRAN (R 4.3.0)\n#>  recipes    * 1.0.10  2024-02-18 [1] CRAN (R 4.3.1)\n#>  rlang        1.1.3   2024-01-10 [1] CRAN (R 4.3.1)\n#>  rsample    * 1.2.1   2024-03-25 [1] CRAN (R 4.3.1)\n#>  tibble     * 3.2.1   2023-03-20 [1] CRAN (R 4.3.0)\n#>  tidymodels * 1.2.0   2024-03-25 [1] CRAN (R 4.3.1)\n#>  tune       * 1.2.0   2024-03-20 [1] CRAN (R 4.3.1)\n#>  workflows  * 1.1.4   2024-02-19 [1] CRAN (R 4.3.1)\n#>  yardstick  * 1.3.1   2024-03-21 [1] CRAN (R 4.3.1)\n#> \n#>  [1] /Users/emilhvitfeldt/Library/R/arm64/4.3/library\n#>  [2] /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library\n#> \n#> ────────────────────────────────────────────────────────────────────\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}