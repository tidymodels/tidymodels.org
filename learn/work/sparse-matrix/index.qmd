---
title: "Model tuning using a sparse matrix"
categories:
 - tuning
 - classification
 - sparse data
type: learn-subsection
weight: 1
description: | 
  Fitting a model using tidymodels with a sparse matrix as the data.
toc: true
toc-depth: 2
include-after-body: ../../../resources.html
---

```{r}
#| label: "setup"
#| include: false
#| message: false
#| warning: false
source(here::here("common.R"))
```
  
```{r}
#| label: "load"
#| include: false
library(tidymodels)
library(sparsevctrs)

pkgs <- c("tidymodels", "sparsevctrs")

theme_set(theme_bw() + theme(legend.position = "top"))
```

## Introduction

`r article_req_pkgs(pkgs)`

This article demonstrates how we can use a sparse matrix in tidymodels.

## Example data

The data we will be using in this article is a larger sample of the [small_fine_foods](https://modeldata.tidymodels.org/reference/small_fine_foods.html) data set from the [modeldata](https://modeldata.tidymodels.org) package. Data was downloaded from <https://snap.stanford.edu/data/web-FineFoods.html>, slides down to 100,000 rows, tokenized and saved as a sparse matrix. Data has been saved as [reviews.rds](reviews.rds) and code to generate this data set is found at [generate-data.R](generate-data.R). This file takes up around 1MB compressed, and around 12MB once loaded into R.

This data set is encoded as a sparse matrix from the Matrix package. We are using this data for this article because if we were to turn it into a dense matrix it would take up 3GB which is a considerable size.

```{r}
#| label: "read-data"
reviews <- readr::read_rds("reviews.rds")
reviews |> head()
```

## Modeling

We start by loading tidymodels and the sparsevctrs package. The sparsevctrs package includes some helper functions that will allow us to more easily work with sparse matrices in tidymodels.

```{r}
#| label: "load-packages"
library(tidymodels)
library(sparsevctrs)
```

While sparse matrices now work parsnip, recipes, and workflows directly. If we turn it into a tibble we can use rsample's sampling functions as well. Calling `as_tibble()` would be uncomfortable as it would take up 3GB. We can however use the `coerce_to_sparse_tibble()` from the sparsevctrs package. This will create a tibble with sparse columns. We call that a **sparse tibble**.

```{r}
#| label: "sparse-tibble"
reviews_tbl <- coerce_to_sparse_tibble(reviews)
reviews_tbl
```

Despite this tibble contains 15,000 rows and a little under 25,000 columns it only takes up marginally more space than the sparse matrix.

```{r}
#| label: "sizes"
lobstr::obj_size(reviews)
lobstr::obj_size(reviews_tbl)
```

The outcome `SCORE` is currently encoded as a double, but we want it to be a factor for it to work well with tidymodels.

```{r}
#| label: "outcome-factor"
reviews_tbl <- reviews_tbl |>
  mutate(SCORE = factor(SCORE, levels = c(1, 0), labels = c("great", "other")))
```

Since `reviews_tbl` is now a tibble, we can use `initial_split()` as we usually do.

```{r}
#| label: "data-splitting"
set.seed(1234)

review_split <- initial_split(reviews_tbl)
review_train <- training(review_split)
review_test <- testing(review_split)

review_folds <- vfold_cv(review_train)
```

Next, we will specify our workflow. Since we are showcasing how sparse data works in tidymodels, we will stick to a simple lasso regression model. These models tend to work well with sparse predictors. `penalty` has been set to be tuned.

```{r}
#| label: "workflow"
rec_spec <- recipe(SCORE ~ ., data = review_train)

lm_spec <- logistic_reg(penalty = tune()) |>
  set_engine("glmnet")

wf_spec <- workflow(rec_spec, lm_spec)
```

With everything in order, we can now fit the different models with `tune_grid()`.

```{r}
#| label: "tune-grid"
tune_res <- tune_grid(wf_spec, review_folds)
```

This should run in a reasonable amount of time. Once that is done, then we can look at the performance for different values of regularization, to make sure that the optimal value was within the range we searched.

```{r}
#| label: "autoplot"
autoplot(tune_res)
```

It appears that it did, so we finalize the workflows and fit the final model on the training data set.

```{r}
#| label: "finalize-workflow"
wf_final <- finalize_workflow(
 wf_spec, 
  select_best(tune_res, metric = "roc_auc")
 )

wf_fit <- fit(wf_final, review_train)
```

With this fitted model, we can now predict with a sparse tibble.

```{r}
#| label: "predict"
predict(wf_fit, review_test)
```

## Session information {#session-info}

```{r}
#| label: "si"
#| echo: false
small_session(pkgs)
```
